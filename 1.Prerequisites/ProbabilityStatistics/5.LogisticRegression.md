&emsp;
# Logistic Regression
- 知乎：[机器学习 逻辑（对数几率）回归算法](https://zhuanlan.zhihu.com/p/416281720)
- 知乎：[用人话讲明白逻辑回归 Logistic regression](https://zhuanlan.zhihu.com/p/139122386)
- 知乎：[【机器学习】逻辑回归（非常详细）](https://zhuanlan.zhihu.com/p/74874291)
- 知乎：[简单的交叉熵损失函数，你真的懂了吗？](https://zhuanlan.zhihu.com/p/38241764)



&emsp;
# 1 Logistic 分布与 sigmoid 函数
Logistic 分布是一种连续型的概率分布
- $\mu$: 位置参数
- $\gamma$: 形状参数

>PDF（Probability Distribution Function）

$$f(x) = F'(x) = \frac{e^{-(x-\mu)/ \gamma}}{\gamma(1+e^{-(x-\mu)/ \gamma})^2}$$

>CDF（Cumulative Distribution Function）
- $\mu=0，\gamma=1$ 就是 sigmoid 函数
$$F(x) =\int^{+\infty}_{-\infty} f(x)dx= P(X \leq x) = \frac{1}{1+e^{-(x-\mu)/\gamma}}$$

<div align=center>
    <image src='imgs/logistic.png' width=600>
</div>



&emsp;
# 2 Logistic 回归

二分类问题是一个 Binormial Distribution
$$P(Y=1 | x) = p(x)$$
$$P(Y=0 | x) = 1 - p(x)$$

概率函数：
$$P(X=k) = p^k(1-p)^{1-k}， k=0, 1$$
似然函数：
$$L(w) = \prod[p(x_i)]^{y_i}[1 - p(x_i)]^{1-y_i}$$

根据极大似然估计的老套路，两边求对数，写成对数似然函数

$$\ lnL(w) = \sum\Bigg[y_i lnp(x_i) + \Big(1-y_i\Big)ln\Big(1-p(x_i)\Big) \Bigg]$$
$$\qquad = \sum\Bigg[y_i ln\frac{p(x_i)}{1-p(x_i)} + ln\Big(1-p(x_i)\Big) \Bigg]$$
$$= \sum\Bigg[y_i(w\cdot x_i) - ln\Big(1+e^{w \cdot x_i}\Big) \Bigg]$$



$$J(w) = -\frac{1}{N}lnL(w)$$

