&emsp;
# Model Pruning
- 相关论文：Learning Efficient Convolutional Networks through Network Slimming (ICCV 2017)

>引言
- 考虑一个问题，深度学习模型里面的卷积层出来之后的特征有非常多，这里面会不会存在一些没有价值的特征及其相关的连接？又如何去判断一个特征及其连接是否有价值？

&emsp;
  
先给出答案: 在 Batch Normalize 层的缩放因子上施加 L1 正则化
>优点
- 不需要对现有 CNN 架构进行任何更改
- 使用 L1 正则化将 BN 缩放因子的值推向零
  - 使我们能够识别不重要的通道（或神经元），因为每个缩放因子对应于特定的卷积通道（或全连接层的神经元）
  - 这有利于在接下来的步骤中进行通道级剪枝
- 附加的正则化项很少会损害性能。不仅如此，在某些情况下，它会导致更高的泛化精度
- 剪枝不重要的通道有时可能会暂时降低性能，但这个效应可以通过接下来的修剪网络的微调来弥补
- 剪枝后，由此得到的较窄的网络在模型大小、运行时内存和计算操作方面比初始的宽网络更加紧凑。上述过程可以重复几次，得到一个多通道网络瘦身方案，从而实现更加紧凑的网络


&emsp;
# 1 损失函数

$$L = \sum_{(x,y)} l\Big(f(x, W), y\Big) + \lambda\sum_{\gamma \in \Gamma} g(\gamma)$$
- 对 $\gamma$ 进行 L1 正则化

&emsp;
# 2 具体流程

<div align=center>
    <image src="./imgs/process.png" width=700>
</div>


&emsp;
## 2.1 Baseline Training
这一步的训练就是非常普通的训练过程，为了获得原模型的训练权重，可以拿来作为一个对比的基准，也可以拿来进行稀疏训练

任何一个预训练模型的 .pt 文件跟这个过程是等价的


&emsp;
## 2.2 Training with sparsity
稀疏训练

>核心代码
- 参数 s 就是前面提到的 $\lambda$
```py
# additional subgradient descent on the sparsity-induced penalty term
def updateBN():
    for m in model.modules():
        if isinstance(m, nn.BatchNorm2d):
            m.weight.grad.data.add_(
                args.s*torch.sign(m.weight.data)
            )  # L1

def train(epoch):
    ...
    if args.sr:
        updateBN()
    ...
```




&emsp;
## 2.3 Prune
对模型进行剪枝，主要针对有参数的层：Conv2d、BatchNorm2d、Linear，Pool2d 的层只用来做下采样，没有可学习的参数，不用处理

>cfg 和 cfg_mask
- 前面对 BatchNorm 进行了稀疏训练
- 获取所有 BatchNorm 的参数数量，将 BatchNorm 所有参数取出来排序
- 根据剪枝比例 $r$ 设置 threshold，通过 `gt()`（greater than）方法得到 mask，小于 threshold 的置零
- 根据 mask 计算剩余的数量，记录
  - cfg: 用于创建新模型
  - cfg_mask: 用于剪枝
- 后面会用到两个 mask，操作每一层的输入与输出

<div align=center>
    <image src="imgs/CBP.png" width=1000>
</div>

>Conv2d
- weights: (out_channels, in_channels, kernel_size, kernel_size)
- 利用 mask 做索引，对应赋值
- 使用 start_mask、end_mask


&emsp;
>BatchNorm2d
- self.weight: 存储 $\gamma$，(input_size)
- self.bias: 存储 $\beta$, (input_size)
- 使用 end_mask
- 更新 start_mask、end_mask

&emsp;
>Linear
- self.weight: (out_features, in_features)
- self.bias: (out_features)
- 使用 start_mask

<div align=center>
    <image src="imgs/batch_forward.png" >
</div>
&emsp;


## 2.4 Finetune
(略)
